#!/usr/bin/env python3
"""
Git Merge Orchestrator - æµ‹è¯•ç»“æœéªŒè¯è„šæœ¬
éªŒè¯æµ‹è¯•æ‰§è¡Œç»“æœçš„æ­£ç¡®æ€§
"""

import os
import json
import subprocess
from pathlib import Path


class TestResultVerifier:
    """æµ‹è¯•ç»“æœéªŒè¯å™¨"""

    def __init__(self, test_base_dir):
        self.test_base_dir = Path(test_base_dir)
        self.verification_results = []

    def verify_all_scenarios(self):
        """éªŒè¯æ‰€æœ‰æµ‹è¯•åœºæ™¯çš„ç»“æœ"""
        print("ğŸ” å¼€å§‹éªŒè¯æµ‹è¯•ç»“æœ...")
        print("=" * 50)

        scenarios_to_verify = [
            ("merge-conflicts-test", self._verify_merge_conflicts),
            ("file-level-test", self._verify_file_level_processing),
            ("load-balancing-test", self._verify_load_balancing),
            ("ignore-rules-test", self._verify_ignore_rules),
        ]

        for repo_name, verify_func in scenarios_to_verify:
            repo_path = self.test_base_dir / "test-repos" / repo_name

            if not repo_path.exists():
                print(f"â­ï¸ è·³è¿‡ä¸å­˜åœ¨çš„ä»“åº“: {repo_name}")
                continue

            print(f"\nğŸ“‹ éªŒè¯åœºæ™¯: {repo_name}")
            print("-" * 30)

            try:
                result = verify_func(repo_path)
                self.verification_results.append(
                    {
                        "scenario": repo_name,
                        "success": result,
                        "details": self._get_verification_details(repo_path),
                    }
                )

                status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
                print(f"{status}")

            except Exception as e:
                print(f"âŒ éªŒè¯å¼‚å¸¸: {e}")
                self.verification_results.append(
                    {"scenario": repo_name, "success": False, "error": str(e)}
                )

        self._print_verification_summary()
        return all(r["success"] for r in self.verification_results)

    def _verify_merge_conflicts(self, repo_path):
        """éªŒè¯åˆå¹¶å†²çªåœºæ™¯"""
        # æ£€æŸ¥åˆå¹¶è®¡åˆ’æ˜¯å¦å­˜åœ¨
        plan_file = repo_path / ".merge_work" / "merge_plan.json"
        if not plan_file.exists():
            print("  âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨")
            return False

        try:
            with open(plan_file) as f:
                plan_data = json.load(f)

            # éªŒè¯åŸºæœ¬ç»“æ„
            if not self._validate_plan_structure(plan_data):
                print("  âŒ åˆå¹¶è®¡åˆ’ç»“æ„æ— æ•ˆ")
                return False

            # æ£€æŸ¥è„šæœ¬ç”Ÿæˆ
            scripts_dir = repo_path / ".merge_work" / "scripts"
            if not scripts_dir.exists() or not list(scripts_dir.glob("*.sh")):
                print("  âŒ æœªç”Ÿæˆåˆå¹¶è„šæœ¬")
                return False

            print("  âœ… åˆå¹¶è®¡åˆ’å’Œè„šæœ¬ç”Ÿæˆæ­£å¸¸")
            return True

        except json.JSONDecodeError:
            print("  âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶æ ¼å¼é”™è¯¯")
            return False

    def _verify_file_level_processing(self, repo_path):
        """éªŒè¯æ–‡ä»¶çº§å¤„ç†"""
        plan_file = repo_path / ".merge_work" / "merge_plan.json"
        if not plan_file.exists():
            print("  âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨")
            return False

        try:
            with open(plan_file) as f:
                plan_data = json.load(f)

            # éªŒè¯æ–‡ä»¶çº§ç»“æ„
            if plan_data.get("processing_mode") != "file_level":
                print("  âŒ å¤„ç†æ¨¡å¼ä¸æ˜¯ file_level")
                return False

            if "files" not in plan_data or not isinstance(plan_data["files"], list):
                print("  âŒ ç¼ºå°‘æ–‡ä»¶çº§æ•°æ®ç»“æ„")
                return False

            # éªŒè¯æ–‡ä»¶ä¿¡æ¯ç»“æ„
            files = plan_data["files"]
            if not files:
                print("  âŒ æœªå¤„ç†ä»»ä½•æ–‡ä»¶")
                return False

            for file_info in files[:3]:  # æ£€æŸ¥å‰3ä¸ªæ–‡ä»¶
                required_fields = ["path", "assignee", "status"]
                if not all(field in file_info for field in required_fields):
                    print(f"  âŒ æ–‡ä»¶ä¿¡æ¯ç¼ºå°‘å¿…éœ€å­—æ®µ: {file_info}")
                    return False

            print(f"  âœ… æ–‡ä»¶çº§å¤„ç†æ­£å¸¸ï¼Œå¤„ç†äº† {len(files)} ä¸ªæ–‡ä»¶")
            return True

        except json.JSONDecodeError:
            print("  âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶æ ¼å¼é”™è¯¯")
            return False

    def _verify_load_balancing(self, repo_path):
        """éªŒè¯è´Ÿè½½å‡è¡¡"""
        plan_file = repo_path / ".merge_work" / "merge_plan.json"
        if not plan_file.exists():
            print("  âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨")
            return False

        try:
            with open(plan_file) as f:
                plan_data = json.load(f)

            # ç»Ÿè®¡è´Ÿè½½åˆ†é…
            assignee_workload = {}

            if plan_data.get("processing_mode") == "file_level":
                for file_info in plan_data.get("files", []):
                    assignee = file_info.get("assignee", "æœªåˆ†é…")
                    if assignee != "æœªåˆ†é…":
                        assignee_workload[assignee] = (
                            assignee_workload.get(assignee, 0) + 1
                        )
            else:
                for group in plan_data.get("groups", []):
                    assignee = group.get("assignee", "æœªåˆ†é…")
                    if assignee != "æœªåˆ†é…":
                        file_count = len(group.get("files", []))
                        assignee_workload[assignee] = (
                            assignee_workload.get(assignee, 0) + file_count
                        )

            if not assignee_workload:
                print("  âŒ æœªè¿›è¡Œä»»åŠ¡åˆ†é…")
                return False

            if len(assignee_workload) < 2:
                print("  âš ï¸ è´Ÿè½½å‡è¡¡éªŒè¯ï¼šåªåˆ†é…ç»™äº†1ä¸ªäºº")
                return True  # ä»ç„¶ç®—é€šè¿‡ï¼Œå¯èƒ½æ˜¯åˆç†çš„æƒ…å†µ

            # è®¡ç®—è´Ÿè½½åˆ†é…çš„å‡è¡¡æ€§
            workloads = list(assignee_workload.values())
            max_workload = max(workloads)
            min_workload = min(workloads)
            balance_ratio = min_workload / max_workload if max_workload > 0 else 0

            print(f"  âœ… è´Ÿè½½åˆ†é…ï¼š{len(assignee_workload)} ä¸ªè´¡çŒ®è€…ï¼Œå¹³è¡¡åº¦ {balance_ratio:.2f}")
            return True

        except json.JSONDecodeError:
            print("  âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶æ ¼å¼é”™è¯¯")
            return False

    def _verify_ignore_rules(self, repo_path):
        """éªŒè¯å¿½ç•¥è§„åˆ™"""
        # æ£€æŸ¥å¿½ç•¥è§„åˆ™æ–‡ä»¶
        ignore_file = repo_path / ".merge_ignore"
        if not ignore_file.exists():
            print("  âŒ .merge_ignore æ–‡ä»¶ä¸å­˜åœ¨")
            return False

        plan_file = repo_path / ".merge_work" / "merge_plan.json"
        if not plan_file.exists():
            print("  âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨")
            return False

        try:
            with open(plan_file) as f:
                plan_data = json.load(f)

            # æ”¶é›†å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
            processed_files = []
            if plan_data.get("processing_mode") == "file_level":
                processed_files = [f["path"] for f in plan_data.get("files", [])]
            else:
                for group in plan_data.get("groups", []):
                    processed_files.extend(group.get("files", []))

            # æ£€æŸ¥æ˜¯å¦åŒ…å«åº”è¯¥è¢«å¿½ç•¥çš„æ–‡ä»¶ç±»å‹
            ignored_extensions = [".pyc", ".log", ".tmp", ".DS_Store"]
            ignored_dirs = ["__pycache__", "node_modules", ".vscode"]

            has_ignored_files = any(
                any(f.endswith(ext) for ext in ignored_extensions)
                or any(dir_name in f for dir_name in ignored_dirs)
                for f in processed_files
            )

            if has_ignored_files:
                print("  âŒ å¿½ç•¥è§„åˆ™å¤±æ•ˆï¼šåŒ…å«åº”å¿½ç•¥çš„æ–‡ä»¶")
                print(f"    å¤„ç†çš„æ–‡ä»¶: {processed_files[:5]}...")  # æ˜¾ç¤ºå‰5ä¸ª
                return False

            print(f"  âœ… å¿½ç•¥è§„åˆ™æ­£å¸¸ï¼šæ­£ç¡®è¿‡æ»¤äº†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¤„ç† {len(processed_files)} ä¸ªæ–‡ä»¶ï¼‰")
            return True

        except json.JSONDecodeError:
            print("  âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶æ ¼å¼é”™è¯¯")
            return False

    def _validate_plan_structure(self, plan_data):
        """éªŒè¯åˆå¹¶è®¡åˆ’çš„åŸºæœ¬ç»“æ„"""
        required_fields = ["source_branch", "target_branch", "timestamp"]

        # æ£€æŸ¥åŸºæœ¬å­—æ®µ
        if not all(field in plan_data for field in required_fields):
            return False

        # æ£€æŸ¥æ•°æ®ç»“æ„
        processing_mode = plan_data.get("processing_mode", "group_based")

        if processing_mode == "file_level":
            return "files" in plan_data and isinstance(plan_data["files"], list)
        else:
            return "groups" in plan_data and isinstance(plan_data["groups"], list)

    def _get_verification_details(self, repo_path):
        """è·å–éªŒè¯è¯¦ç»†ä¿¡æ¯"""
        details = {}

        # æ£€æŸ¥åˆå¹¶è®¡åˆ’
        plan_file = repo_path / ".merge_work" / "merge_plan.json"
        if plan_file.exists():
            try:
                with open(plan_file) as f:
                    plan_data = json.load(f)

                details["processing_mode"] = plan_data.get("processing_mode", "unknown")
                details["source_branch"] = plan_data.get("source_branch", "unknown")
                details["target_branch"] = plan_data.get("target_branch", "unknown")

                if plan_data.get("processing_mode") == "file_level":
                    details["files_count"] = len(plan_data.get("files", []))
                else:
                    details["groups_count"] = len(plan_data.get("groups", []))

            except json.JSONDecodeError:
                details["plan_file_error"] = "JSONæ ¼å¼é”™è¯¯"

        # æ£€æŸ¥è„šæœ¬ç”Ÿæˆ
        scripts_dir = repo_path / ".merge_work" / "scripts"
        if scripts_dir.exists():
            details["generated_scripts"] = len(list(scripts_dir.glob("*.sh")))

        return details

    def _print_verification_summary(self):
        """æ‰“å°éªŒè¯æ‘˜è¦"""
        print("\n" + "=" * 50)
        print("ğŸ“Š æµ‹è¯•ç»“æœéªŒè¯æ‘˜è¦")
        print("=" * 50)

        total_scenarios = len(self.verification_results)
        successful_scenarios = sum(1 for r in self.verification_results if r["success"])

        print(f"éªŒè¯åœºæ™¯æ•°: {total_scenarios}")
        print(f"æˆåŠŸéªŒè¯: {successful_scenarios}")
        print(f"å¤±è´¥éªŒè¯: {total_scenarios - successful_scenarios}")
        print(
            f"æˆåŠŸç‡: {successful_scenarios/total_scenarios*100:.1f}%"
            if total_scenarios > 0
            else "0%"
        )

        print("\nåœºæ™¯è¯¦æƒ…:")
        for result in self.verification_results:
            status = "âœ…" if result["success"] else "âŒ"
            scenario = result["scenario"]
            print(f"  {status} {scenario}")

            if "details" in result:
                details = result["details"]
                if "processing_mode" in details:
                    print(f"      æ¨¡å¼: {details['processing_mode']}")
                if "files_count" in details:
                    print(f"      æ–‡ä»¶æ•°: {details['files_count']}")
                elif "groups_count" in details:
                    print(f"      ç»„æ•°: {details['groups_count']}")
                if "generated_scripts" in details:
                    print(f"      è„šæœ¬æ•°: {details['generated_scripts']}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="Git Merge Orchestrator æµ‹è¯•ç»“æœéªŒè¯")
    parser.add_argument(
        "--test-dir",
        default="/home/howie/Workspace/Project/tools/git-merge-orchestrator-test",
        help="æµ‹è¯•ç›®å½•è·¯å¾„",
    )
    parser.add_argument("--scenario", help="éªŒè¯ç‰¹å®šåœºæ™¯ï¼ˆå¯é€‰ï¼‰")

    args = parser.parse_args()

    verifier = TestResultVerifier(args.test_dir)

    if args.scenario:
        # éªŒè¯ç‰¹å®šåœºæ™¯
        repo_path = Path(args.test_dir) / "test-repos" / args.scenario
        if not repo_path.exists():
            print(f"âŒ åœºæ™¯ä¸å­˜åœ¨: {args.scenario}")
            return False

        print(f"ğŸ” éªŒè¯åœºæ™¯: {args.scenario}")
        # è¿™é‡Œå¯ä»¥æ‰©å±•å•ä¸ªåœºæ™¯çš„éªŒè¯é€»è¾‘
        return True
    else:
        # éªŒè¯æ‰€æœ‰åœºæ™¯
        success = verifier.verify_all_scenarios()
        return success


if __name__ == "__main__":
    import sys

    success = main()
    sys.exit(0 if success else 1)
