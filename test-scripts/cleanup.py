#!/usr/bin/env python3
"""
Git Merge Orchestrator - æµ‹è¯•ç¯å¢ƒæ¸…ç†å·¥å…·
æ¸…ç†æµ‹è¯•ä»“åº“ã€æ—¥å¿—æ–‡ä»¶å’Œä¸´æ—¶æ•°æ®
"""

import os
import sys
import argparse
import shutil
from pathlib import Path
import json
from datetime import datetime


class TestCleanupTool:
    """æµ‹è¯•æ¸…ç†å·¥å…·"""

    def __init__(self, base_dir):
        self.base_dir = Path(base_dir)
        self.test_repos_dir = self.base_dir / "test-repos"
        self.logs_dir = self.base_dir / "logs"
        self.scenarios_dir = self.base_dir / "scenarios"

    def cleanup_all(self, confirm=True):
        """æ¸…ç†æ‰€æœ‰æµ‹è¯•æ•°æ®"""
        if confirm:
            print("âš ï¸ è¿™å°†åˆ é™¤æ‰€æœ‰æµ‹è¯•ä»“åº“ã€æ—¥å¿—å’Œåœºæ™¯æ•°æ®ï¼")
            response = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(yes/NO): ")
            if response.lower() not in ["yes", "y"]:
                print("âŒ å–æ¶ˆæ¸…ç†æ“ä½œ")
                return

        print("ğŸ§¹ å¼€å§‹æ¸…ç†æ‰€æœ‰æµ‹è¯•æ•°æ®...")

        cleaned_items = []

        # æ¸…ç†æµ‹è¯•ä»“åº“
        if self.test_repos_dir.exists():
            repo_count = len([d for d in self.test_repos_dir.iterdir() if d.is_dir()])
            shutil.rmtree(self.test_repos_dir)
            self.test_repos_dir.mkdir()
            cleaned_items.append(f"æµ‹è¯•ä»“åº“: {repo_count} ä¸ª")

        # æ¸…ç†æ—¥å¿—
        if self.logs_dir.exists():
            log_count = len([f for f in self.logs_dir.iterdir() if f.is_file()])
            shutil.rmtree(self.logs_dir)
            self.logs_dir.mkdir()
            cleaned_items.append(f"æ—¥å¿—æ–‡ä»¶: {log_count} ä¸ª")

        # æ¸…ç†åœºæ™¯ä¿¡æ¯
        if self.scenarios_dir.exists():
            scenario_count = len(
                [f for f in self.scenarios_dir.iterdir() if f.is_file()]
            )
            shutil.rmtree(self.scenarios_dir)
            self.scenarios_dir.mkdir()
            cleaned_items.append(f"åœºæ™¯æ–‡ä»¶: {scenario_count} ä¸ª")

        print("âœ… æ¸…ç†å®Œæˆ:")
        for item in cleaned_items:
            print(f"   - {item}")

    def cleanup_repos(self, repo_names=None, confirm=True):
        """æ¸…ç†æŒ‡å®šçš„æµ‹è¯•ä»“åº“"""
        if not self.test_repos_dir.exists():
            print("ğŸ“‹ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•ä»“åº“ç›®å½•")
            return

        if repo_names is None:
            # æ¸…ç†æ‰€æœ‰ä»“åº“
            repos_to_clean = [d for d in self.test_repos_dir.iterdir() if d.is_dir()]
            if confirm:
                print(f"âš ï¸ å°†åˆ é™¤ {len(repos_to_clean)} ä¸ªæµ‹è¯•ä»“åº“")
                response = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(yes/NO): ")
                if response.lower() not in ["yes", "y"]:
                    print("âŒ å–æ¶ˆæ¸…ç†æ“ä½œ")
                    return
        else:
            # æ¸…ç†æŒ‡å®šä»“åº“
            repos_to_clean = []
            for repo_name in repo_names:
                repo_path = self.test_repos_dir / repo_name
                if repo_path.exists():
                    repos_to_clean.append(repo_path)
                else:
                    print(f"âš ï¸ ä»“åº“ä¸å­˜åœ¨: {repo_name}")

        if not repos_to_clean:
            print("ğŸ“‹ æ²¡æœ‰æ‰¾åˆ°è¦æ¸…ç†çš„ä»“åº“")
            return

        print(f"ğŸ§¹ æ¸…ç† {len(repos_to_clean)} ä¸ªæµ‹è¯•ä»“åº“...")

        cleaned_count = 0
        for repo_path in repos_to_clean:
            try:
                repo_size = self._get_directory_size(repo_path)
                shutil.rmtree(repo_path)
                cleaned_count += 1
                print(f"   âœ… å·²åˆ é™¤: {repo_path.name} ({self._format_size(repo_size)})")
            except Exception as e:
                print(f"   âŒ åˆ é™¤å¤±è´¥: {repo_path.name} - {e}")

        print(f"âœ… ä»“åº“æ¸…ç†å®Œæˆ: {cleaned_count} ä¸ªä»“åº“å·²åˆ é™¤")

    def cleanup_logs(self, older_than_days=None, confirm=True):
        """æ¸…ç†æ—¥å¿—æ–‡ä»¶"""
        if not self.logs_dir.exists():
            print("ğŸ“‹ æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—ç›®å½•")
            return

        log_files = [f for f in self.logs_dir.iterdir() if f.is_file()]

        if older_than_days:
            # åªæ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ—¥å¿—
            cutoff_time = datetime.now().timestamp() - (older_than_days * 24 * 3600)
            files_to_clean = [f for f in log_files if f.stat().st_mtime < cutoff_time]
            print(f"ğŸ§¹ æ¸…ç†è¶…è¿‡ {older_than_days} å¤©çš„æ—¥å¿—æ–‡ä»¶...")
        else:
            # æ¸…ç†æ‰€æœ‰æ—¥å¿—
            files_to_clean = log_files
            if confirm:
                print(f"âš ï¸ å°†åˆ é™¤ {len(files_to_clean)} ä¸ªæ—¥å¿—æ–‡ä»¶")
                response = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(yes/NO): ")
                if response.lower() not in ["yes", "y"]:
                    print("âŒ å–æ¶ˆæ¸…ç†æ“ä½œ")
                    return

        if not files_to_clean:
            print("ğŸ“‹ æ²¡æœ‰æ‰¾åˆ°è¦æ¸…ç†çš„æ—¥å¿—æ–‡ä»¶")
            return

        cleaned_count = 0
        total_size = 0
        for log_file in files_to_clean:
            try:
                file_size = log_file.stat().st_size
                log_file.unlink()
                cleaned_count += 1
                total_size += file_size
                print(f"   âœ… å·²åˆ é™¤: {log_file.name} ({self._format_size(file_size)})")
            except Exception as e:
                print(f"   âŒ åˆ é™¤å¤±è´¥: {log_file.name} - {e}")

        print(f"âœ… æ—¥å¿—æ¸…ç†å®Œæˆ: {cleaned_count} ä¸ªæ–‡ä»¶å·²åˆ é™¤ (å…± {self._format_size(total_size)})")

    def cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        print("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")

        temp_patterns = [
            "**/*.pyc",
            "**/__pycache__",
            "**/.DS_Store",
            "**/Thumbs.db",
            "**/*.tmp",
            "**/*.temp",
            "**/*.log.bak",
        ]

        cleaned_count = 0
        total_size = 0

        for pattern in temp_patterns:
            for item in self.base_dir.rglob(pattern):
                try:
                    if item.is_file():
                        size = item.stat().st_size
                        item.unlink()
                        total_size += size
                    elif item.is_dir():
                        size = self._get_directory_size(item)
                        shutil.rmtree(item)
                        total_size += size

                    cleaned_count += 1
                    print(f"   âœ… å·²åˆ é™¤: {item.relative_to(self.base_dir)}")
                except Exception as e:
                    print(f"   âŒ åˆ é™¤å¤±è´¥: {item.relative_to(self.base_dir)} - {e}")

        if cleaned_count == 0:
            print("ğŸ“‹ æ²¡æœ‰æ‰¾åˆ°ä¸´æ—¶æ–‡ä»¶")
        else:
            print(
                f"âœ… ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ: {cleaned_count} ä¸ªé¡¹ç›®å·²åˆ é™¤ (å…± {self._format_size(total_size)})"
            )

    def list_test_data(self):
        """åˆ—å‡ºæµ‹è¯•æ•°æ®æ¦‚å†µ"""
        print("ğŸ“Š æµ‹è¯•æ•°æ®æ¦‚å†µ:")
        print("=" * 60)

        # æµ‹è¯•ä»“åº“
        if self.test_repos_dir.exists():
            repos = [d for d in self.test_repos_dir.iterdir() if d.is_dir()]
            if repos:
                print(f"\\nğŸ“ æµ‹è¯•ä»“åº“ ({len(repos)} ä¸ª):")
                total_repo_size = 0
                for repo in sorted(repos):
                    repo_size = self._get_directory_size(repo)
                    total_repo_size += repo_size
                    print(f"   {repo.name:30} {self._format_size(repo_size):>10}")
                print(f"   {'æ€»è®¡':30} {self._format_size(total_repo_size):>10}")
            else:
                print("\\nğŸ“ æµ‹è¯•ä»“åº“: æ— ")

        # æ—¥å¿—æ–‡ä»¶
        if self.logs_dir.exists():
            logs = [f for f in self.logs_dir.iterdir() if f.is_file()]
            if logs:
                print(f"\\nğŸ“‹ æ—¥å¿—æ–‡ä»¶ ({len(logs)} ä¸ª):")
                total_log_size = 0
                for log in sorted(logs, key=lambda x: x.stat().st_mtime, reverse=True):
                    log_size = log.stat().st_size
                    total_log_size += log_size
                    mod_time = datetime.fromtimestamp(log.stat().st_mtime).strftime(
                        "%Y-%m-%d %H:%M"
                    )
                    print(
                        f"   {log.name:30} {self._format_size(log_size):>10} {mod_time}"
                    )
                print(f"   {'æ€»è®¡':30} {self._format_size(total_log_size):>10}")
            else:
                print("\\nğŸ“‹ æ—¥å¿—æ–‡ä»¶: æ— ")

        # åœºæ™¯ä¿¡æ¯
        if self.scenarios_dir.exists():
            scenarios = [f for f in self.scenarios_dir.iterdir() if f.is_file()]
            if scenarios:
                print(f"\\nğŸ¯ åœºæ™¯ä¿¡æ¯ ({len(scenarios)} ä¸ª):")
                for scenario in sorted(scenarios):
                    scenario_name = scenario.stem
                    try:
                        with open(scenario, "r", encoding="utf-8") as f:
                            data = json.load(f)
                            scenario_type = data.get("type", "unknown")
                            print(f"   {scenario_name:30} {scenario_type}")
                    except:
                        print(f"   {scenario_name:30} (æ— æ³•è¯»å–)")
            else:
                print("\\nğŸ¯ åœºæ™¯ä¿¡æ¯: æ— ")

        print("=" * 60)

    def _get_directory_size(self, path):
        """è·å–ç›®å½•å¤§å°"""
        total_size = 0
        try:
            for dirpath, dirnames, filenames in os.walk(path):
                for filename in filenames:
                    file_path = os.path.join(dirpath, filename)
                    if os.path.exists(file_path):
                        total_size += os.path.getsize(file_path)
        except (OSError, PermissionError):
            pass
        return total_size

    def _format_size(self, size_bytes):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes == 0:
            return "0 B"

        size_units = ["B", "KB", "MB", "GB"]
        unit_index = 0
        size = float(size_bytes)

        while size >= 1024 and unit_index < len(size_units) - 1:
            size /= 1024
            unit_index += 1

        return f"{size:.1f} {size_units[unit_index]}"

    def vacuum_git_repos(self):
        """ä¼˜åŒ–Gitä»“åº“ï¼Œå‡å°‘ç£ç›˜å ç”¨"""
        print("ğŸ”§ ä¼˜åŒ–Gitä»“åº“...")

        if not self.test_repos_dir.exists():
            print("ğŸ“‹ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•ä»“åº“ç›®å½•")
            return

        repos = [
            d
            for d in self.test_repos_dir.iterdir()
            if d.is_dir() and (d / ".git").exists()
        ]

        if not repos:
            print("ğŸ“‹ æ²¡æœ‰æ‰¾åˆ°Gitä»“åº“")
            return

        optimized_count = 0
        total_saved = 0

        for repo in repos:
            try:
                # è·å–ä¼˜åŒ–å‰çš„å¤§å°
                before_size = self._get_directory_size(repo)

                # æ‰§è¡ŒGitä¼˜åŒ–å‘½ä»¤
                import subprocess

                subprocess.run(
                    ["git", "gc", "--prune=now"], cwd=repo, capture_output=True
                )
                subprocess.run(["git", "repack", "-ad"], cwd=repo, capture_output=True)

                # è·å–ä¼˜åŒ–åçš„å¤§å°
                after_size = self._get_directory_size(repo)
                saved = before_size - after_size

                if saved > 0:
                    total_saved += saved
                    print(f"   âœ… {repo.name}: èŠ‚çœ {self._format_size(saved)}")
                else:
                    print(f"   ğŸ“‹ {repo.name}: å·²ä¼˜åŒ–")

                optimized_count += 1

            except Exception as e:
                print(f"   âŒ ä¼˜åŒ–å¤±è´¥ {repo.name}: {e}")

        if optimized_count > 0:
            print(
                f"âœ… Gitä»“åº“ä¼˜åŒ–å®Œæˆ: {optimized_count} ä¸ªä»“åº“ï¼Œå…±èŠ‚çœ {self._format_size(total_saved)}"
            )


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Git Merge Orchestrator æµ‹è¯•ç¯å¢ƒæ¸…ç†å·¥å…·")

    parser.add_argument("--all", action="store_true", help="æ¸…ç†æ‰€æœ‰æµ‹è¯•æ•°æ®")
    parser.add_argument("--repos", nargs="*", help="æ¸…ç†æŒ‡å®šçš„æµ‹è¯•ä»“åº“")
    parser.add_argument("--logs", action="store_true", help="æ¸…ç†æ—¥å¿—æ–‡ä»¶")
    parser.add_argument("--temp", action="store_true", help="æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
    parser.add_argument("--older-than", type=int, help="æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ–‡ä»¶")
    parser.add_argument("--list", "-l", action="store_true", help="åˆ—å‡ºæµ‹è¯•æ•°æ®æ¦‚å†µ")
    parser.add_argument("--vacuum", action="store_true", help="ä¼˜åŒ–Gitä»“åº“")
    parser.add_argument("--force", "-f", action="store_true", help="å¼ºåˆ¶æ‰§è¡Œï¼Œä¸è¯¢é—®ç¡®è®¤")
    parser.add_argument(
        "--base-dir",
        default="/home/howie/Workspace/Project/tools/git-merge-orchestrator-test",
        help="æµ‹è¯•ç›®å½•åŸºç¡€è·¯å¾„",
    )

    args = parser.parse_args()

    cleanup = TestCleanupTool(args.base_dir)
    confirm = not args.force

    if args.list:
        cleanup.list_test_data()
        return

    if args.all:
        cleanup.cleanup_all(confirm=confirm)
        return

    if args.repos is not None:
        if len(args.repos) == 0:
            # æ¸…ç†æ‰€æœ‰ä»“åº“
            cleanup.cleanup_repos(confirm=confirm)
        else:
            # æ¸…ç†æŒ‡å®šä»“åº“
            cleanup.cleanup_repos(args.repos, confirm=confirm)

    if args.logs:
        cleanup.cleanup_logs(older_than_days=args.older_than, confirm=confirm)

    if args.temp:
        cleanup.cleanup_temp_files()

    if args.vacuum:
        cleanup.vacuum_git_repos()

    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•æ“ä½œï¼Œæ˜¾ç¤ºå¸®åŠ©
    if not any([args.all, args.repos is not None, args.logs, args.temp, args.vacuum]):
        print("è¯·æŒ‡å®šè¦æ‰§è¡Œçš„æ¸…ç†æ“ä½œï¼Œä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©")
        cleanup.list_test_data()


if __name__ == "__main__":
    main()
